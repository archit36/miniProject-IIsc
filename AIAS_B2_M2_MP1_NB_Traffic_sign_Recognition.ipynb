{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9llghv8jX1"
      },
      "source": [
        "# Machine Learning and AI for Autonomous Systems\n",
        "## A program by IISc and TalentSprint\n",
        "### Mini Project: Image classification using MLP and CNN"
      ],
      "id": "Ps9llghv8jX1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maritime-miami"
      },
      "source": [
        "## Learning Objectives"
      ],
      "id": "maritime-miami"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljJR6CwfZN_"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* load and extract features of images\n",
        "\n",
        "* implement the Multi-Layer perceptron to classify images\n",
        "\n",
        "* implement CNN using keras"
      ],
      "id": "nljJR6CwfZN_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29152de7"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Traffic sign recognition is a challenging, real-world problem relevant for AI based transportation systems. Traffic signs show a wide range of variations between classes in terms of color, shape, and the presence of pictograms or text. However, there exist subsets of\n",
        "classes (e.g., speed limit signs) that are very similar to each other. Further, the classifier\n",
        "has to be robust against large variations in visual appearances due to changes in illumination, partial\n",
        "occlusions, rotations, weather conditions etc. Using a comprehensive traffic sign detection dataset, here we will perform classification of traffic signs, train and evaluate the different models and compare to the performance of MLPs."
      ],
      "id": "29152de7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58facc94"
      },
      "source": [
        "![img](https://paperswithcode.com/media/datasets/GTSRB-0000000633-9ce3c5f6_Dki5Rsf.jpg)"
      ],
      "id": "58facc94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "surprising-uruguay"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The data for this mini-project is from the German Traffic Sign Detection Benchmark [GTSDB](https://benchmark.ini.rub.de/gtsdb_dataset.html). This archive contains the training set used during the IJCNN 2013 competition.\n",
        "\n",
        "The German Traffic Sign Detection Benchmark is a single-image detection assessment for researchers with interest in the field of computer vision, pattern recognition and image-based driver assistance. It is introduced on the IEEE International Joint Conference on Neural Networks 2013.\n",
        "\n",
        "It features ...\n",
        "\n",
        "* The main archive FullIJCNN2013.zip includes the images (1360 x 800 pixels) in PPM format, the image sections containing only the traffic signs\n",
        "* A file in CSV format with the ground truth\n",
        "* A ReadMe.txt with more details."
      ],
      "id": "surprising-uruguay"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ],
      "id": "ih-oasWmdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfWGmjNHdZul"
      },
      "source": [
        "To build and improve upon a machine learning model for the classification of images and achieve a high accuracy final model."
      ],
      "id": "qfWGmjNHdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "operating-latter"
      },
      "source": [
        "## Grading = 10 Points"
      ],
      "id": "operating-latter"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "812a816f",
        "cellView": "form"
      },
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "!unzip -qq FullIJCNN2013.zip"
      ],
      "id": "812a816f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import Required packages"
      ],
      "id": "abstract-stocks"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advisory-knowing"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.io import imread, imshow\n",
        "from sklearn import preprocessing\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization"
      ],
      "id": "advisory-knowing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4bF_GJdZuo"
      },
      "source": [
        "###**Excercise 1**\n",
        "\n",
        "### Data Loading and Feature Extraction (1 points)\n",
        "\n",
        "#### Get the features and labels of data\n",
        "\n",
        "* Extract the features of the images\n",
        "* Extract labels of the images\n",
        "* Resize the images to (30, 30) and convert to numpy 1-D array\n",
        "\n",
        "   Hint: [Link](https://machinelearningmastery.com/how-to-load-and-manipulate-images-for-deep-learning-in-python-with-pil-pillow/)"
      ],
      "id": "gp4bF_GJdZuo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc5c2362"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "fc5c2362",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUY3yNrdaABY"
      },
      "source": [
        "###**Excercise 2**\n",
        "### Data Exploration and Preprocessing ( 2 points)"
      ],
      "id": "NUY3yNrdaABY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ca63666"
      },
      "source": [
        "#### Plot the sample image of each class\n",
        "\n",
        "Hint: plt.subplot"
      ],
      "id": "9ca63666"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c414e14e"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "c414e14e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2rqCM-sIbY"
      },
      "source": [
        "#### Plot the distribution of Classes"
      ],
      "id": "8a2rqCM-sIbY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwWKGQMFsIDP"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "nwWKGQMFsIDP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37b23a0b"
      },
      "source": [
        "#### Normalize the features\n",
        "\n",
        "For most image data, the pixel values are integers with values between 0 and 255.\n",
        "\n",
        "Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values.\n",
        "\n",
        "Hint: sklearn.preprocessing.normalize"
      ],
      "id": "37b23a0b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82239736"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "82239736",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MRpw70ikBwA"
      },
      "source": [
        "###**Excercise 3**\n",
        "### Train the MLP classifier on features (3 points)\n",
        "\n",
        "* Split the data into train and test\n",
        "\n",
        "* Train the MLP classifier with different parameters\n",
        "\n",
        "* Get the accuracy score and performance metrics"
      ],
      "id": "_MRpw70ikBwA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af9cd34e"
      },
      "source": [
        "\n",
        "\n",
        "* Define the keras model and initialize the layers\n",
        "  - Ensure the input layer has the right number of input features. This can be specified when creating the first layer with the input_dim argument.\n",
        "* Compile the model\n",
        "  - Specify the loss function (to evaluate a set of weights), the optimizer (is used to search through different weights for the network) and any optional metrics to collect and report during training.\n",
        "* Fit and Evaluate the model\n",
        "  - Fit the data by specifying epochs and evaluate the model"
      ],
      "id": "af9cd34e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbfQyg61jEbv"
      },
      "source": [
        "# Step 1 - Build the architecture\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "qbfQyg61jEbv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xy1y2eXjEby"
      },
      "source": [
        "# Step 2 - Compile the model\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5xy1y2eXjEby"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_LTVFlfjEb1"
      },
      "source": [
        "# Step 3 - Fit and Evaluate the model\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2_LTVFlfjEb1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "911d0a39"
      },
      "source": [
        "#### Try the different algorithms and compare the results with MLP classifier"
      ],
      "id": "911d0a39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-FSvc27_64O"
      },
      "source": [
        "###**Excercise 4**\n",
        "### Train a CNN classifier on images (4 points)\n",
        "\n",
        "* Split the data into train and test\n",
        "\n",
        "* Train the CNN with 2D convolution and Maxpooling layers\n",
        "\n",
        "* Get the accuracy score on train and test sets"
      ],
      "id": "G-FSvc27_64O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Guawf8U_64S"
      },
      "source": [
        "\n",
        "\n",
        "* Define the keras model and initialize the layers\n",
        "  - Ensure the input layer is specified with correct image size as input. This can be specified when creating the first layer with the input_shape argument.\n",
        "* Speicify number of filters Kernel size, Pool size and activation function\n",
        "  - filters,kernel_size and activation arguments of Conv2D layer can be used\n",
        "  - pool_size argument of MaxPool2D can be used to set Pool size\n",
        "* Compile the model\n",
        "  - Specify the loss function (to evaluate a set of weights), the optimizer (is used to search through different weights for the network) and any optional metrics to collect and report during training.\n",
        "* Fit and Evaluate the model\n",
        "  - Fit the data by specifying epochs and evaluate the model"
      ],
      "id": "0Guawf8U_64S"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eMm6CWljLnm"
      },
      "source": [
        "# Step 1 - Build the architecture\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "-eMm6CWljLnm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2R8QP0EjLnn"
      },
      "source": [
        "# Step 2 - Compile the model\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "r2R8QP0EjLnn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvAPL9YjLno"
      },
      "source": [
        "# Step 3 - Fit and Evaluate the model\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ugvAPL9YjLno"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAHzeVx_tImO"
      },
      "source": [
        "#### Experiment using Dropout, Regularization and Batch Normalization"
      ],
      "id": "IAHzeVx_tImO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w34gbejXvLUs"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "w34gbejXvLUs",
      "execution_count": null,
      "outputs": []
    }
  ]
}